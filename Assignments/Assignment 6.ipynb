{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9959efe",
   "metadata": {},
   "source": [
    "# Grid World Visualization--Part I\n",
    "Consider a grid world modeled using a 2D numpy array of dimension of $10\\times 10$. There are 10 robots moving in the field. Write a function, named `display_grid` that takes the current locations of all robots as inputs, and displays the locations of all robots. Use appropriate plot to display the locations, and clearly label your plot. Read the documentation of `xlim` and `ylim`, and use them to make sure that the whole grid can be displayed in your plot.\n",
    "\n",
    "An example of robot locations, i.e., input to the function, is given below:\n",
    "\n",
    "```py\n",
    " location = np.array([[9 8],\n",
    "                    [8 7],\n",
    "                    [9 3],\n",
    "                    [4 3],\n",
    "                    [3 1],\n",
    "                    [3 2],\n",
    "                    [2 7],\n",
    "                    [4 4],\n",
    "                    [0 0],\n",
    "                    [5 4]])\n",
    "```\n",
    "Each row of the input array corresponds to an agent. The first column represents the row indices of all agents, and the second column represents the column indices of all agents in the field. An exmaple output is given below:\n",
    "![Example output](assets/robot_location.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6770a0",
   "metadata": {},
   "source": [
    "# Grid World Visualization--Part II\n",
    "Each robot can take one out of four actions: [\"up\", \"down\", \"left\", \"right\"], indicating the direction towards which the robot will move. If the moving direction will make the robot go outside the boundary of the grid world, then the robot will remain at its current location.\n",
    "\n",
    "Write a function named `update_location` that takes the current location and action of a robot as inputs, and return its updated location. Feel free to verify your code by plotting the locations of robot before and after taking actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d3651",
   "metadata": {},
   "source": [
    "# Infectious Disease Visualization\n",
    "Revise your function \"simulate_disease\" from previous assignment to achieve the following goals. The function should print out the statistic information of the infection probability at the end of prediction horizon, including minimum, maximum, average, and standard deviation.\n",
    "\n",
    "The function should also plot how the infection probabilities of all individuals evolve over the prediction horizon. Pick appropriate visualization plot and clearly label your plot. You do not need to generate legends for the plot. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61204c74",
   "metadata": {},
   "source": [
    "# Image Downsampling\n",
    "Write a function named `downsample_image`. The function takes a grayscale image and an integer downsampling rate as input and outputs a filtered version of the image. The input image is represented by a 2D numpy array. You can assume the image is of a square shape, and the image size is larger than downsampling rate. To downsample the image, we follow the steps below:\n",
    "- Partition the image into a collection of smaller blocks. Each block is of dimension $k\\times k$, where $k$ is the downsampling rate. If the original image is of dimension $N\\times N$, then the rows and columns are partitions into $\\frac{N}{k}$ segments, respectively. The output image should then be of dimension $\\frac{N}{k}\\times \\frac{N}{k}$.\n",
    "- For each block associated with $i$-th row segment, and $j$-th column segment, calculate the average of all pixels within the block, and the average is $(i,j)$-th pixel in output image is assigned as the average. \n",
    "\n",
    "\n",
    "Your function should display the downsampled image. An example of the downsampling process is given below:\n",
    "![downsample process](assets/filter.gif)\n",
    "\n",
    "The red block in this example is sometimes referred to as a kernel. The kernel in this example is known as a moving average filter. \n",
    "\n",
    "Please use this image to test your function. Although this is a colorful image, you can convert it to grayscale using the code below and then pass it to the function:\n",
    "\n",
    "```py\n",
    "from PIL import Image\n",
    "img = Image.open('sample_image_2.jpg').convert('L') # load image in gray scale\n",
    "img_array = np.array(img) # 8-bit code grayscale\n",
    "```\n",
    "See an example of downsampled image with downsampling rate=5:\n",
    "\n",
    "![downsampled image](assets/dsimg.png)\n",
    "\n",
    "\n",
    "Revise your function to downsample a colorful image. Note that a colorful image can be represented as a 3D numpy array, where the 3rd dimension represents the RGB channels.\n",
    "\n",
    "**Extra challenge** (this challenge is not graded): This challenge will test your code efficiency. You need to improve your code to achieve runtime . Please use the following code to test your efficiency:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b47420",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit -n 1 -r 7 img_ds2 = downsample_image(image=img_array, downsampling_rate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb31774",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "LLMs represent words as high dimensional vectors (also known as embeddings). You’ll explore how simple embeddings can capture semantic meanings. Example embeddings of a limited vocabulary are provided below.\n",
    "- Can you propose a metric to measure the similarity between a pair of words? **Hint**: You have seen a measure in previous assignments.\n",
    "- Choose an appropriate visualization to show which words are most similar to each other.\n",
    "- What word do you obtain for `king – man + woman` using vector arithmetic? Does this result make sense to you? Why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {\n",
    "  \"king\": [\n",
    "    1.0, 1.0, 1.0, 0.0, 0.8, 0.9, 0.0, 0.0, 0.0, 0.0\n",
    "  ] + [0.0]*40,\n",
    "  \"queen\": [\n",
    "    1.0, -1.0, 1.0, 0.0, 0.8, 0.9, 0.0, 0.0, 0.0, 0.0\n",
    "  ] + [0.0]*40,\n",
    "  \"man\": [\n",
    "    0.0, 1.0, 1.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0\n",
    "  ] + [0.0]*40,\n",
    "  \"woman\": [\n",
    "    0.0, -1.0, 1.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0\n",
    "  ] + [0.0]*40,\n",
    "  \"apple\": [\n",
    "    0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7, 0.2, 0.6, 0.2\n",
    "  ] + [0.0]*40,\n",
    "  \"banana\": [\n",
    "    0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6, 0.8, 0.6, 0.7\n",
    "  ] + [0.0]*40\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
